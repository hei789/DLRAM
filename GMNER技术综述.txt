================================================================================
GMNER（Grounded Multimodal Named Entity Recognition）技术综述
================================================================================

【概述】
GMNER（基础多模态命名实体识别）是信息抽取领域的新兴任务，旨在从配对的图像-文本中同时提取命名实体、识别其实体类型，并将文本实体定位到图像中的具体视觉区域（边界框）。该任务输出三元组：(文本实体, 实体类型, 视觉区域坐标)。

================================================================================
一、典型技术方法
================================================================================

1. 早期方法（2022-2023）
--------------------------------------------------------------------------------
1.1 基于目标检测的两阶段方法
   - 使用预训练目标检测器（如Faster R-CNN、YOLO）提取图像中的视觉对象
   - 将检测到的对象与文本实体进行对齐
   - 局限性：受限于检测器的词汇表，难以处理细粒度实体类别

1.2 基于跨模态对齐的方法
   - 通过注意力机制实现文本词与图像区域的软对齐
   - 使用对比学习拉近匹配的文本-图像特征
   - 代表性工作：基于Transformer的多模态编码器架构

1.3 序列标注范式
   - 将MNER视为标准的序列标注任务（BIO标注方案）
   - 融合视觉特征辅助文本编码
   - 局限性：难以处理嵌套实体和重叠实体

2. 核心数据集
--------------------------------------------------------------------------------
   - Twitter-2015 / Twitter-2017：标准MNER基准数据集
   - Twitter-GMNER：首个GMNER数据集，包含边界框标注
   - Twitter-SMNER：分段式多模态NER数据集
   - FMNERG：细粒度多模态NER与定位数据集

================================================================================
二、前沿技术方法（2024-2026）
================================================================================

1. RiVEG：LLM作为桥梁（ACL 2024 Findings）
--------------------------------------------------------------------------------
【论文】LLMs as Bridges: Reformulating Grounded Multimodal Named Entity Recognition
【作者】Li et al.
【核心思想】将GMNER重新表述为联合MNER-VE-VG任务

【技术细节】
   - MNER（多模态命名实体识别）：识别文本中的实体
   - VE（视觉蕴含）：判断文本实体是否可在图像中定位
   - VG（视觉定位）：将可定位实体映射到图像边界框

【创新点】
   - 使用LLM作为桥梁解决图像-文本弱相关性问题
   - 区分粗粒度指代表达和细粒度命名实体
   - 提出实体扩展表达（EEE）和视觉蕴含模块处理不可定位实体

【性能】在三个子任务上分别提升10.65%、6.21%和8.83%
【代码】https://github.com/JinYuanLi0012/RiVEG

--------------------------------------------------------------------------------

2. GEM：细粒度实体映射器（EMNLP 2024 Findings）
--------------------------------------------------------------------------------
【论文】Granular Entity Mapper: Advancing Fine-grained Multimodal Named Entity Recognition and Grounding
【核心思想】利用MLLM进行细粒度实体识别，摆脱对预训练目标检测器的依赖

【技术细节】
   - 使用LVLM（大视觉语言模型）作为隐式定位器
   - 无需边界框训练即可实现开放词汇视觉实体定位
   - 通过MLLM重排序处理层次化实体类别信息
   - 采用外部LLM知识增强多粒度实体识别

【创新点】
   - 解决长尾分布问题
   - 处理不同大小的视觉实体
   - 知识增强的细粒度识别

【适用数据集】GMNER、FMNERG

--------------------------------------------------------------------------------

3. UnCo：不确定性驱动的协作框架（EMNLP 2025）
--------------------------------------------------------------------------------
【论文】UnCo: Uncertainty-Driven Collaborative Framework of Large and Small Models for Grounded Multimodal NER
【作者】Tang et al.
【核心思想】小模型与大模型的两阶段协作

【技术细节】
   阶段1：小模型+统一不确定性估计（UE）
   - 对未见过的实体表达"我不知道"
   - 将高不确定性预测委托给MLLM

   阶段2：不确定性感知的层次化校正
   - 引导MLLM利用开放域知识优化预测

【优势】保留小模型的域内知识，同时利用MLLM处理未知样本

--------------------------------------------------------------------------------

4. ReFineG：低资源GMNER（CCKS 2025）
--------------------------------------------------------------------------------
【论文】ReFineG: Synergizing Small Supervised Models and LLMs for Low-Resource Grounded Multimodal NER
【成绩】CCKS2025 GMNER共享任务第二名（F1: 0.6461）
【核心思想】三阶段协同框架

【技术细节】
   阶段1（训练）：域感知NER数据合成
   - 将LLM知识迁移到小模型
   - 避免域知识冲突

   阶段2（精修）：基于不确定性的机制
   - 保留高置信度预测
   - 将不确定预测委托给MLLM

   阶段3（定位）：多模态上下文选择算法
   - 通过类比推理增强视觉定位

--------------------------------------------------------------------------------

5. MAKAR：多智能体知识增强推理（EMNLP 2025）
--------------------------------------------------------------------------------
【论文】Multi-Agent Knowledge-Augmented Reasoning for Grounded Multimodal Named Entity Recognition
【核心思想】三个协作智能体架构

【技术细节】
   - KEA（知识增强智能体）：利用内在知识生成初步候选实体
   - ECA（实体校正智能体）：使用外部知识/网络搜索修正低置信度样本
   - ERGA（实体推理定位智能体）：基于增强知识进行渐进式实体定位推理

【解决的问题】
   - 多义词导致的语义歧义
   - 简短实体名称的语义信息有限

【训练方法】SFT初始化 + GRPO（组相对策略优化）

--------------------------------------------------------------------------------

6. MQSPN：多粒度查询引导集预测网络（2024）
--------------------------------------------------------------------------------
【论文】Multi-Grained Query-Guided Set Prediction Network for Grounded Multimodal Named Entity Recognition
【作者】Tang et al.
【核心思想】非自回归并行预测

【技术细节】
   - MQS（多粒度查询集）：结合类型粒度和可学习实体粒度查询
   - 集预测范式：消除暴露偏差
   - QFNet（查询引导融合网络）：连接各组件

【性能】在细粒度GMNER上F1提升2.83%

--------------------------------------------------------------------------------

7. MINIGE-MNER：基因编辑启发的多阶段交互网络（Neural Networks 2026）
--------------------------------------------------------------------------------
【论文】MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition
【核心思想】模拟基因编辑机制的多阶段交互

【技术细节】
   - 基因敲除模块：使用变分信息瓶颈过滤模态噪声
   - 基因重组：最大化模态间互信息，实现细粒度语义对齐
   - 文本主导融合：避免过度依赖可能掩盖文本上下文的视觉信息

【性能】
   - Twitter-2015: 76.45% F1（提升0.83%）
   - Twitter-2017: 88.67% F1（提升0.42%）

--------------------------------------------------------------------------------

8. DSE-HOF：双重相似性增强混合正交融合（Pattern Recognition 2026）
--------------------------------------------------------------------------------
【论文】Dual similarity enhanced hybrid orthogonal fusion for multimodal named entity recognition
【核心思想】解决跨模态融合中的语义退化和特征冗余问题

【技术细节】
   - 词级相似性：过滤相关图像区域
   - 模态级相似性：控制视觉特征整合
   - 正交融合：减少冗余特征同时保留语义关系

【性能】
   - Twitter-2015: 平均提升1.398%
   - Twitter-2017: 平均提升1.681%

--------------------------------------------------------------------------------

9. 多级对齐的对比预训练（ICMR 2024）
--------------------------------------------------------------------------------
【核心思想】文本-图像和实体-对象的多级对齐

【技术细节】
   - 使用扩散模型进行回译生成视觉表示
   - 从与文本实体提示对齐的潜在图像对象生成软伪标签
   - 对比预训练框架

================================================================================
三、关键技术趋势
================================================================================

1. 大模型集成（MLLM Integration）
   - 从纯微调转向小模型与大模型的混合方法
   - 使用MLLM/ LVLM作为隐式定位器

2. 不确定性量化（Uncertainty Quantification）
   - 利用不确定性估计决定何时委托给大模型
   - 代表性工作：UnCo、ReFineG

3. 集预测范式（Set Prediction）
   - 从自回归生成转向并行集预测
   - 消除暴露偏差，支持非自回归解码

4. 细粒度识别（Fine-grained Recognition）
   - 关注长尾分布和细微视觉实体
   - 层次化实体类别处理

5. 知识增强（Knowledge Augmentation）
   - 结合内部模型知识和外部网络检索
   - 解决多义词和语义歧义

6. 视觉蕴含（Visual Entailment）
   - 使用VE模块判断图像是否支持文本声明
   - 区分可定位和不可定位实体

7. 噪声过滤（Noise Filtering）
   - 门控机制、信息瓶颈、正交投影
   - 处理不相关视觉特征

8. 强化学习对齐（RL-based Alignment）
   - 使用GRPO等策略优化方法
   - 更好的实体-视觉区域对齐

================================================================================
四、主要挑战
================================================================================

1. 语义歧义（Semantic Ambiguity）
   - 多义词和长尾分布问题
   - 实体类型的细粒度区分

2. 模态噪声（Modality Noise）
   - 不相关视觉特征可能误导文本实体识别
   - 图像-文本弱相关性

3. 不可定位实体（Ungroundable Entities）
   - 文本中存在但图像中没有对应区域的实体
   - 需要准确识别和过滤

4. 细粒度识别（Fine-grained Recognition）
   - 相似实体子类型的区分
   - 特定类型的组织、人物等

5. 目标检测限制（Object Detection Limitations）
   - 传统OD方法限制词汇表
   - 难以处理细粒度类别

================================================================================
五、代表性论文列表
================================================================================

[1] Li et al. "LLMs as Bridges: Reformulating Grounded Multimodal Named Entity Recognition." ACL 2024 Findings.

[2] Tang et al. "UnCo: Uncertainty-Driven Collaborative Framework of Large and Small Models for Grounded Multimodal NER." EMNLP 2025.

[3] Tang et al. "ReFineG: Synergizing Small Supervised Models and LLMs for Low-Resource Grounded Multimodal NER." CCKS 2025.

[4] "Granular Entity Mapper: Advancing Fine-grained Multimodal Named Entity Recognition and Grounding." EMNLP 2024 Findings.

[5] Tang et al. "Multi-Grained Query-Guided Set Prediction Network for Grounded Multimodal Named Entity Recognition." 2024.

[6] "Multi-Agent Knowledge-Augmented Reasoning for Grounded Multimodal Named Entity Recognition." EMNLP 2025.

[7] "MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition." Neural Networks, 2026.

[8] "Dual similarity enhanced hybrid orthogonal fusion for multimodal named entity recognition." Pattern Recognition, 2026.

[9] "Contrastive Pre-training with Multi-level Alignment for Grounded Multimodal Named Entity Recognition." ICMR 2024.

[10] "An Effective Span-based Multimodal Named Entity Recognition with Consistent Cross-Modal Alignment." LREC 2024.

================================================================================
六、代码资源
================================================================================

- RiVEG: https://github.com/JinYuanLi0012/RiVEG
- GMNER相关数据集可在GitHub搜索"GMNER"获取

================================================================================
文档生成时间：2026年2月
================================================================================
