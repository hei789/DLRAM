# 预训练模块改进建议

## 当前方法评价

当前实现基本满足了"预训练.md"中的要求，但在以下方面可以进一步优化：

---

## 建议修改项

### 1. 细粒度特征提取优化

**当前问题**：
- 当前代码中实体和目标特征提取过于简化，实际使用整句/整图特征代替
- 没有真正实现基于bbox的局部特征提取

**建议方案**：
- 实体特征：根据实体在文本中的字符位置，映射到对应的token位置，提取span-level特征
- 目标特征：根据bbox裁剪图片区域，单独编码每个目标区域
- 可考虑使用RoI Align或简单的Crop+Resize策略

```python
# 示例代码思路
def extract_entity_features(hidden_states, token_positions):
    # 提取实体对应token的mean/max pooling特征
    entity_tokens = hidden_states[:, start_pos:end_pos, :]
    return entity_tokens.mean(dim=1)

def extract_object_features(image, bboxes):
    # 裁剪每个bbox区域并编码
    object_features = []
    for bbox in bboxes:
        cropped = image.crop(bbox)
        feat = encode_image(cropped)
        object_features.append(feat)
    return torch.stack(object_features)
```

---

### 2. 负例构造多样化

**当前问题**：
- 仅使用遮盖后的图片作为负例，负例类型单一
- 缺少跨样本负例（batch内其他样本的图片作为负例）

**建议方案**：
- **跨样本负例**：使用batch内其他样本的图片作为自然负例
- **硬负例挖掘**：选择与正例相似度较高的样本作为困难负例
- **多类型遮盖**：随机遮盖、目标感知遮盖、中心遮盖等多种策略混合

```python
# 硬负例挖掘思路
def hard_negative_mining(text_features, image_features, num_negatives=15):
    similarity = torch.matmul(text_features, image_features.T)
    # 排除对角线（正例）
    mask = torch.eye(len(text_features)).bool()
    similarity_masked = similarity.masked_fill(mask, -float('inf'))
    # 选择相似度最高的负例
    _, hard_neg_indices = torch.topk(similarity_masked, num_negatives, dim=1)
    return hard_neg_indices
```

---

### 3. 动态遮盖策略

**当前问题**：
- 需要预先生成遮盖图片，存储开销大
- 遮盖策略固定，缺乏灵活性

**建议方案**：
- 在训练时**动态生成**遮盖，参考MAE（Masked Autoencoder）的随机patch掩码策略
- 可配置遮盖比例、遮盖区域大小、遮盖形状等参数

```python
def dynamic_mask(image, mask_ratio=0.3, patch_size=16):
    """动态掩码：随机遮盖image patch"""
    # 将图片分成patches，随机选择部分遮盖
    # 可使用随机噪声、零值或均值填充
    pass
```

---

### 4. 损失函数改进

**当前问题**：
- 仅使用基础InfoNCE损失
- 粗粒度和细粒度损失的权重固定

**建议方案**：
- **自适应温度参数**：让温度参数可学习（当前已实现）或根据训练进度调整
- **动态权重**：根据训练阶段动态调整粗粒度/细粒度损失的权重
- **引入对比学习变体**：如Supervised Contrastive Loss、ArcFace等

```python
# 动态权重示例
def get_loss_weights(epoch, total_epochs):
    # 前期侧重粗粒度，后期侧重细粒度
    coarse_weight = max(0.3, 1.0 - epoch / total_epochs)
    fine_weight = min(1.0, 0.5 + epoch / total_epochs)
    return coarse_weight, fine_weight
```

---

### 5. 梯度累积与更大Batch Size

**当前问题**：
- Batch Size=16对显存要求较高（约8GB）
- 对比学习通常需要较大的batch size（N=128/256）才能发挥效果

**建议方案**：
- 实现**梯度累积**，在显存受限的情况下模拟更大的batch size
- 或使用梯度检查点（gradient checkpointing）节省显存

```python
# 梯度累积示例
accumulation_steps = 4  # 每4个batch更新一次参数
for i, batch in enumerate(dataloader):
    loss = model(batch) / accumulation_steps
    loss.backward()
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

---

### 6. 跨模态注意力机制

**当前问题**：
- 文本和视觉特征独立编码后进行对比
- 缺乏细粒度的跨模态交互

**建议方案**：
- 在投影层之前添加**跨模态Transformer层**，让文本token和图像patch相互关注
- 或使用**门控融合机制**结合两种模态的信息

```python
class CrossModalAttention(nn.Module):
    def __init__(self, d_model, n_heads):
        super().__init__()
        self.cross_attn = nn.MultiheadAttention(d_model, n_heads)

    def forward(self, text_features, image_features):
        # text作为query，image作为key/value
        fused, _ = self.cross_attn(text_features, image_features, image_features)
        return fused
```

---

### 7. 数据增强策略

**当前问题**：
- 缺少对图片和文本的数据增强

**建议方案**：
- **图像增强**：随机裁剪、颜色抖动、RandAugment等
- **文本增强**：同义词替换、回译（back-translation）等
- 注意：增强后的样本应视为正例

---

### 8. 评估指标完善

**当前问题**：
- 仅提供了基础的图文检索评估

**建议方案**：
- 增加**细粒度对齐评估**：实体-目标匹配准确率
- 增加**可视化分析**：展示注意力热力图、特征相似度矩阵等
- 定期保存最佳模型（基于验证集指标）

---

## 优先级建议

| 优先级 | 修改项 | 影响 | 实现难度 |
|--------|--------|------|----------|
| 高 | 细粒度特征提取优化 | 显著提升细粒度对齐效果 | 中 |
| 高 | 梯度累积 | 支持更大batch，提升对比学习效果 | 低 |
| 中 | 负例构造多样化 | 提升对比学习质量 | 中 |
| 中 | 动态遮盖策略 | 减少存储开销，增加灵活性 | 中 |
| 中 | 数据增强 | 提升泛化能力 | 低 |
| 低 | 跨模态注意力 | 可能提升但计算开销大 | 高 |
| 低 | 损失函数改进 | 微调优化 | 低 |

---

## 注意事项

1. 细粒度预训练需要实体-目标配对标注，如果数据中没有准确的bbox对应关系，可能需要先进行数据清洗或对齐
2. 动态遮盖可能会增加训练时间，需要权衡存储和计算开销
3. 建议先在小数据集上验证改进效果，再在全量数据上训练
