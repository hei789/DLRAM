# 任务
整理用于对比学习的数据。对比学习有两个层次，分别是“图片-文本”层次和“实体-目标”层次。
# 数据源
## 存放文本、实体、对应图片ID
Json 文件夹下
## 存放所有图片
Images 文件夹下
## 存放在图片中识别出的目标文件
在Twitter10000_v2.0/xml 文件夹下
# 正例
## “文本-图片”层次
Json文件夹下，每个元素中，“content”对应文本，“img_id”对应的Images文件夹下的图片
## “实体-目标”层次
Json文件夹下，每个元素中，"ans"下的“ent”的值对应实体，“img_id”对应的Xml文件夹下xml文件中，存有实体对应的视觉目标的boundding_box
# 负例
## “文本-图片”层次
采用基于视觉反思机制，由于需要进行“以实体为中心”的Grounded Multimodal Named Entity Recognition(GMNER)任务。所以，采用遮盖法构建负例。在Npz文件夹下，有很多利用VinVL目标识别出的结果，为了方便你理解，我读取了一个放在VinVL_Result.txt文件中，但你记住其仍然是npz文件。
通过遮盖VinVL识别出的目标，来构成负例。如果构建出的负例不足15个，则选择score高的再构建一遍补充。我建议的流程是：（1）读取npz文件，根据"bounding_boxes"对应的坐标框进行遮盖（2）如果不足15个，则根据"scores"选择得分更高的进行补充。
## “实体-目标”层次
正例构建出后，随机挑选其他目标图片中的15个构成负例。
# 输出
python代码，用于构建两个数据集
## 正例
### 文本-图片层次
一个数据集，有两个文件夹，一个文件夹存放Json，表示文本及对应img_id；另一个存放图片
### 实体-目标层次
一个数据集，两个文件夹，一个文件夹存放Json，表示实体及其对应裁剪出的图片Id，另一个文件夹存放从数据中裁剪出的目标图片，也是jpg格式
## 负例
### 文本-图片层次
一个数据集，其只有一个文件夹，存放Json，表示文本、对应img_id、需要遮盖的boundding_box
### 实体-目标层次
一个数据集，其只有一个文件夹，存放Json，表示实体、正例中对应的img_id，负例中的img_id数组
