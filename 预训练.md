# 预训练
## 概述
任务 ：“文本-视觉”模态表征对齐
模型设置 ：选择BERT-base作为文本编码器，ViT-B/16作为视觉编码器，文本和视觉特征经过编码后都选择特殊标签[CLS]的表征作为整体特征。（模型使用限定路径，请在README中提供模型下载方法）
训练函数 ：对比学习。对于一个图文对，用于对比学习的例子数量为N，正例数量1个，负例数量N - 1个。例如，N为16，则是1个正例，15个负例。
## 方法
粗粒度：文本-图片层面 
正例 ：文本 - 其对应图片原图
负例 ：文本 - 其对应图片经过遮盖后的图片（这些图片会事先放在一个文件夹中）
细粒度：实体-目标层面 
正例 ：实体 - 其对应视觉目标
负例 ：实体 - 其他视觉目标
## 输出
python的torch 1.9 版本源代码，README
